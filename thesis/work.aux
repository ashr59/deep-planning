\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}}
\newlabel{Abstract}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation and outline of methods.}{2}}
\newlabel{Motivation and outline of methods.}{{2}{2}}
\citation{Bengio09}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background on Auto-encoders}{4}}
\newlabel{Background on Auto-encoders}{{3}{4}}
\citation{Vincint08}
\citation{Hinton06}
\citation{Hawkins04}
\@writefile{toc}{\contentsline {section}{\numberline {4}0.1 Stacked de-noising autoencoders}{6}}
\newlabel{Stacked de-noising autoencoders}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An SdA with two autoencoders. Each autoencoder is a a simple three layer network. The input/output to the first layer is the pink level, and the yellow level is it's distributed code, or hidden layer. The yellow hidden layer is then used as input/output to another autoencoder, it's hidden layer is shown in green.}}{7}}
\citation{Le12}
\citation{Bergstra10}
\@writefile{toc}{\contentsline {section}{\numberline {5}1.0 Successes of SdAs on machine perception tasks}{8}}
\newlabel{Successes of SdAs on machine perception tasks}{{5}{8}}
\citation{Baker95}
\@writefile{toc}{\contentsline {section}{\numberline {6}1.1 Applications of SdAs to planning tasks}{9}}
\newlabel{Applications of SdAs to planning tasks}{{6}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {7}2.0 Plausibility of SdA's as a model of the mammalian neocortex}{10}}
\newlabel{Plausibility of SdA's as a model of the mammalian neocortex}{{7}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {8}2.1 Philosophical points}{11}}
\newlabel{Philosophical points}{{8}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {9}3.0 Expected performance of SdA vs greedy approach}{13}}
\newlabel{Expected performance of SdA vs. dA}{{9}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {10}3.2 Training the SdA}{14}}
\newlabel{Training the SdA}{{10}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A representation of the go position that would maximally activate one of the hidden units from the highest level in the SdA. Stones are either colored white or black based on the direction of the prediction, and the opacity is the confidence that a stone would be in that position rather than being empty.}}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {11}3.1 Implementation of Go Engine}{17}}
\newlabel{Implementation of Go Engine}{{11}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {12}4.0 Performance of SdA-based player against dA player and various other opponents}{18}}
\newlabel{Performance of SdA-based player against dA player and various other opponents}{{12}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {13}Analysis of the behavior of trained SdA}{19}}
\newlabel{Analysis of the behavior of trained SdA}{{13}{19}}
\bibcite{Baker95}{1}
\bibcite{Bengio07}{2}
\bibcite{Bengio09}{3}
\bibcite{Hawkins04}{4}
\bibcite{Hinton06}{5}
\bibcite{Hinton07}{6}
\bibcite{Bergstra10}{7}
\bibcite{Le12}{8}
\bibcite{Ranzato06}{9}
\bibcite{Vincint08}{10}
\@writefile{toc}{\contentsline {section}{\numberline {14}4.1 Conclusion and lessons learned}{20}}
\newlabel{Conclusion and lessons learned}{{14}{20}}
