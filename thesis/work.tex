\documentclass[11pt]{article}
\usepackage{graphicx}    % needed for including graphics e.g. EPS, PS
\topmargin -1.5cm        % read Lamport p.163
\oddsidemargin -0.04cm   % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth 16.59cm
\textheight 21.94cm 
%\pagestyle{empty}       % Uncomment if don't want page numbers
\parskip 7.2pt           % sets spacing between paragraphs
%\renewcommand{\baselinestretch}{1.5} % Uncomment for 1.5 spacing between lines
\parindent 0pt		 % sets leading space for paragraphs

\begin{document}         
% Start your text
\section{Introduction}
\label{Introduction}

\section{0.0}
\label{Background on de-noising autoencoders}
Autoencoders, or autoassociators as they are sometimes called, are a variant of the simple three-layer artificial neural network where the output is expected to equal the input and the hidden layer is smaller or sparser than than the input layer.

Show figure to explain autoencoder.

Quote most of the formulas and explanations on http://www.deeplearning.net/tutorial/dA.html

Cite the explanation that autoencders with linear activation functions on the neurons do the same thing as PCA.

Explain the necessity of sparisty using the notion of data compression. Cite the evidence that the brain uses sparse representations. 

Explain what makes an autoencoder de-noising and why it is important, especially when stacking them. (leads into next section)


\section{0.1}
\label{Stacked de-noising autoencoders}
Autoencoders are not the same as a deep neural network with many hidden layers, (explain how)

Explain the necessity of a deep network and the curse of dimensionality.

Cite the many new developments in the field of deep nets.

Stacked denoising autoencoders are more complex nerural networks, who's basic component are a variant of those simple, three-layer networks. The are still simple compared to the neocortex, but have some of the same performance characteristics. The neocortex has several layers, but those layers do not correspond to the layers of the stack in a stacked denoising neural autoencoder. An SDA only models the lateral connections that pyramidal cells make between areas of the cortex. Each pyramidal cell is a sort of representative for around 10,000 other neuron's in it's vicinity.  For example, the areas V1 through V4 in the visual cortex are organized in a functional heirarchy, but they are not in a physical stack of layers.

Use a figure to clear up the confusing overlaps of terminology around the word 'layer'

\section{1.0}
\label{Successes of SDAs on machine perception tasks}

Tell the story of Hinton's grad student who kept adding another layer, and cite the proof of the increase in the upper bound on prediction accuracy.

Cite Hinton's work on images, video, sound, and mocap.

Describe the computational requirements.

\section{1.1}
\label{Applications of SDAs to planning tasks}

Find some examples of this

\section{2.0}
\label{Plausibility of SDA's as a model of the mammalian neocortex}

Describe the cortex in general and the heriarchical structure of the primate visual cortex.

Cite the case of autoencoders which were trained to see performing well on hearing tasks, and how this platicity is also a feature of the cortex.

Describe the different phases of learning, and how they resemble the phases in a person's maturation.

\section{2.1}
\label{Philosophical points}

Describe how the levels in the SDA are levels of abstraction, and possibility, and utility, of having a root at the top of this tree.

\section{3.0}
\label{Expected performace of SDA vs. DA on the competitive growth game, Puerto Rico}

\section{3.1}
\label{implementaion of Puerto Rico}

The rules of the board game, Puerto Rico, with a minor variation proposed by it's author Andreas Seyfarth to balance the game, were encoded in Python 2.7. The implementation was stictly functional, though Python is not a strictly functional language. It was chosen for it's rapid prototyping and bug-repellant qualities. There is a data structure to represent the game state, and a data structure to represent a move. There are functions to take a move, and a gamestate, and produce the next game state. 


Why was Puerto Rico chosen?
* It is a complex problem of competetive growth relevant to today's global economy (even though it's about 17th century imperial colonialism, the problems are still systemically relevant )
* The greedist move is not always the best move. The greediest move can often help ones opponents quite a bit. Choosing a way of life, and sticking to it is a good strategy, thus a compound plan is needed, with strategic choices at multiple levels of abstraction.
* Additionally, the most sustainable strategy is not the best either, because the game does eventually end, and there is an implicit transition in the middle of the game when players switch to unsustainable exploitation of existing infrastructure. 
* Puerto rico has some randomness in it's initial configuration, but the state transition function is deterministic. 
* The end conditions can be straighforwardly extended for longer games.
* the setup can be straightforwardly generalized to abitrarily many players. Both of these extensions may be needed to make the game more difficut if the SDA masters it too easily, And to create a game for which the brute force approach is infeasable.

\section{3.2}
\label{Implementation of SDA-based decider}

I am operating on the assumtion that perception and planning are both part of the same process. The model of sensory data is influenced by three main factors. The accurcy, the sparsity, and the desirability. In the case of a game this last factor would be the points or wins/losses experienced by the player. The player percieves the state of the game and the state of it's own recent actions, and expects a likely, sparse, and desirable scenario next, and then is made to take any actions it expected of itself which are legal in the rules of the game. It may not be the most brilliant way to play a game, but I think It would at least perform OK at Puerto Rico, and it is interesting for it's behavioral similarity to humans.

\section{4.0}
\label{Performace of SDA-based player against DA player and various other opponents}

performance matrix?
SDA vs. DA
SDA vs. SDA
SDA vs. me
SDA vs. online players who think they are playing a human. (definitely don't have time to do this)

\section{4.1}
\label{Conclusion and lessons learned}










Stacked de-noising autoencoders are a type of deep belief network that can discover arbitrarily deeply nested hierarchical structure in data, loosely based on a hypothetical organization of mammalian neocortex. Geoffrey Hinton et al. have shown that adding another layer to the stack of autoencoders always increases the upper bound on prediction accuracy in machine perception tasks. An autoencoder is a neural network that learns the identity function for given data in a space. Either using fewer hidden nodes than input nodes, or enforcing sparsity causes the network to learn a compressed representation of the input space. Autoencoders are a type of content addressable memory. Autoencoders can be stacked to improve their prediction accuracy. Once a single level auto-encoder is trained, it's hidden node activation levels are used as the input space for another autoencoder. With the addition of the crucial de-noising modification, these stacks of autoencoders become capable of modeling very complex data, and show comparable performance to other deep belief networks (DBN).


Stacked de-noising auto-encoders, and other deep belief networks show much promise in machine perception, they are relatively new, and have a wide range of applicability to AI problems. They may not be an optimal allocation of computational resources in all cases but they show surprisingly human qualities. I want to apply them to planning, because they are powerful and could perform well. Some planning tasks require a sustainable outlook, and many traditional planning algorithms are too greedy. Additionally, in games which end, and for games with an infinite payoff for the winner, and in games in which you can change the rules, a strategic balance between short term and long term solutions must be found. You know how a sustainable strategy can beat a greedy one, but alternatively, a player who uses an exploitative short term tactic can beat a player who sticks to sustainable strategies, because he may win, or change the rules of the game before the time comes to suffer the consequences. An agent who can chain together short periods of exploitation punctuated by changes to the game's rules can achieve an impossibly high rate of growth to an agent who simply simply acts sustainably within the current rules. This type of play would require generating nested plans, and in order to navigate this vasty space, the levels of planning would need to be segmented into say, high level strategy, and low level tactics. A deep belief network planning by "optimistic dreaming", as I describe below, would structure it's model of the possible actions in the game in just this way. Just to be clear, it would not be possible to literally "change the rules" but sub-systems within the DBN may be operating in a sub-game invented by the DBN with more restricted rules than the super-game the whole system is playing.

The task of planning in AI, or strategy building in game theory is a difficult one. The usual way to do it is to search and rank possible futures within computational limits. Planning with a generative deep belief net is simpler. All the work is done during perception, and generating a plan takes about the same amount of time no matter how complex the problem. Generating likely sequences of percepts, or "dreaming" as DBN researchers often call it, is the inverse of perception. All that is required to make a plan is to generate a likely sequence of events using a network that has preferentially remembers sequences of that led to desirable outcomes. This is what I am calling "planning by optimistic dreaming." I will test a planning system that uses a stack of de-noising auto-encoders in this way by allowing it to play a game where there are appropriate risks and rewards and a balance between short and long term solutions is optimal. My current choice is the board game "Puerto Rico" which has themes of sustainability and growth. I plan to encode the rules of Puerto Rico or whatever game I eventually decide to use, into my existing open source networked, turn-based game arbitration software, which I previously used in a Mancala AI competition. I will be building off of the deeplearning.net suite of Python tools to implement the stacked de-noising encoder, and running the system on my personal GPU cluster, if I can get that to work. I will be branching off from the term project I worked on for Will Landecker's advanced machine learning class, so I have some code and results already. I expect the planning task to be computationally simpler than the typical machine perception tasks to which this algorithm is usually applied, so I shouldn't run up against any hard physical limits. I'll be spending about half of my time on writing, and half on coding. In my opinion, publishing freely available, well-documented, running code on the Internet, provides the highest value to the machine learning and systems science communities.

\begin{thebibliography}{99}
\bibitem{lamport} Lamport, L., {\it LaTeX : A Documentation
 Preparation System User's Guide and Reference Manual}, Addison-Wesley 
 Pub Co., 2nd edition, August 1994.
\end{thebibliography}


% Stop your text
\end{document}








